---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hello! I‚Äôm **Yao** **Zhang** (Âº†Áë∂). I am currently a lecturer at the School of Statistics and Data Science, Nankai University.

Before that, I received my Ph.D. (2022) and B.S. (2017) from Nankai University, advised by [Prof. Zhenglu Yang](https://scholar.google.com/citations?user=u5LzNHcAAAAJ&hl=zh-CN). From 2021 to 2022, I was a visiting student at the [NExT](https://www.nextcenter.org/) Research Centre at the National University of Singapore (NUS), where I was mentored by [Prof. Wenqiang Lei](https://scholar.google.com/citations?user=qexdxuEAAAAJ&hl=zh-CN) and [Prof. Chua Tat-Seng](https://scholar.google.com/citations?user=Z9DWCBEAAAAJ&hl=zh-CN).

My primary research interests lie in the area of Statistics and Data Science, with a focus on the following topics:
Knowledge Reasoning; 
Medical NLP; 
Safe AI.



# üî• News
- *2025.04*: &nbsp;üéâüéâüéâ Three papers are accepted by ACL 2025. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2025</div><img src='images/ding25acl.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Generating Questions, Answers, and Distractors for Videos: Exploring Semantic Uncertainty of Object Motions](https://aclanthology.org/2025.findings-acl.376/)

Wenjian Ding, **Yao Zhang**#, Jun Wang, Adam Jatowt, Zhenglu Yang#

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2025</div><img src='images/qin25acl.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Listening to Patients: A Framework of Detecting and Mitigating Patient Misreport for Medical Dialogue Generation](https://aclanthology.org/2025.findings-acl.135/)

Lang Qin, **Yao Zhang**#, Hongru Liang, Adam Jatowt, Zhenglu Yang

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2025</div><img src='images/xiao25acl.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View](https://aclanthology.org/2025.acl-long.852/)

Yongjie Xiao, Hongru Liang, Peixin Qin, **Yao Zhang**, Wenqiang Lei

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DASFAA 2025</div><img src='images/bao25dasfaa.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Enhancing Cross-Lingual Dialogue Summarization through Interpretable Chain-of-Thought](https://dasfaa2025.github.io/#/program/research#short-papers)

Zhongtian Bao, **Yao Zhang**, Jun Wang, Adam Jatowt, and Zhenglu Yang

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">COLING 2024</div><img src='images/ding24coling.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Can we learn question, answer, and distractors all from an image? a new task for multiple-choice visual question answering](https://aclanthology.org/2024.lrec-main.254/)

Wenjian Ding, **Yao Zhang**, Jun Wang, Adam Jatowt, and Zhenglu Yang#

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2024</div><img src='images/dingemnlp24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors](https://aclanthology.org/2024.emnlp-main.88/)

Wenjian Ding, **Yao Zhang**, Jun Wang, Adam Jatowt, and Zhenglu Yang#

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/qin23emnlp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Well begun is half done: Generator-agnostic knowledge pre-selection for knowledge-grounded dialogue](https://aclanthology.org/2023.emnlp-main.285/)

Lang Qin‚àó,**Yao Zhang**#, Hongru Liang, Jun Wang, and Zhenglu Yang#

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2022</div><img src='images/lei22sigir.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Interacting with Non-Cooperative User: A New Paradigm for Proactive Dialogue Policy](https://dl.acm.org/doi/10.1145/3477495.3532001)

Wenqiang Lei*, **Yao Zhang***, Feifan Song, Hongru Liang, Jiaxin Mao, Jiancheng Lv, Zhenglu Yang, Tat-Seng Chua

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2022</div><img src='images/zhang22acl.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Fact-Tree Reasoning for N-ary Question Answering over Knowledge Graphs](https://aclanthology.org/2022.findings-acl.66/)

**Yao Zhang**, Peiyao Li, Hongru Liang, Adam Jatowt, Zhenglu Yang

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2022</div><img src='images/huibin22acl.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension](https://aclanthology.org/2022.acl-long.84/)

Huibin Zhang, Zhengkun Zhang, **Yao Zhang**, Jun Wang, Yufan Li, Ning Jiang, Xin Wei, Zhenglu Yang

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2021</div><img src='images/zhang21emnlp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[GMH: A General Multi-hop Reasoning Model for KG Completion](https://aclanthology.org/2021.emnlp-main.276/)

**Yao Zhang**, Hongru Liang, Adam Jatowt, Wenqiang Lei, Xin Wei, Ning Jiang, Zhenglu Yang

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Ad Hoc Networks 2021</div><img src='images/zhang21adhoc.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TRFR: A ternary relation link prediction framework on Knowledge graphs](https://www.sciencedirect.com/science/article/abs/pii/S1570870520307319)

**Yao Zhang**, Hengpeng Xu, Xu Zhang, Xingxing Wu, Zhenglu Yang

</div>
</div>






